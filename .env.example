# Coordinator configuration
COORDINATOR_HOST=localhost
COORDINATOR_PORT=9000

# Worker hosts configuration
WORKER1_HOST=localhost
WORKER1_PORT=8001

WORKER2_HOST=localhost
WORKER2_PORT=8002
# more workers can be added similarly, note to add it to the coordinator config as well

# Device configuration
DEVICE_TYPE=CPU

# Training parameters
BATCH_SIZE=64
EPOCHS=100
LR_INITIAL=0.001
LR_DECAY_FACTOR=0.75
LR_DECAY_INTERVAL=5

NUM_MICROBATCHES=4

# Logging
LOG_LEVEL=INFO
PROGRESS_PRINT_INTERVAL=100
PROFILER_TYPE=NORMAL
PRINT_LAYER_PROFILING=0
PRINT_LAYER_MEMORY_USAGE=0