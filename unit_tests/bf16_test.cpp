#include <gtest/gtest.h>

#include <cstddef>

#include "device/device_manager.hpp"
#include "nn/blocks_impl/attention_block.hpp"
#include "nn/example_models.hpp"
#include "nn/graph.hpp"
#include "nn/layers.hpp"
#include "nn/layers_impl/dense_layer.hpp"
#include "nn/loss.hpp"
#include "type/type.hpp"

using namespace std;
using namespace tnn;

class BF16Test : public ::testing::Test {
protected:
  void SetUp() override { ExampleModels::register_defaults(); }
};

TEST_F(BF16Test, Dense) {
  constexpr size_t batch_size = 8;
  constexpr size_t input_dim = 32;
  constexpr size_t output_dim = 16;
  auto &allocator = PoolAllocator::instance(getGPU(), defaultFlowHandle);
  Graph graph;

  DenseLayer fp32_dense(input_dim, output_dim, false, "fp32_dense");
  fp32_dense.set_io_dtype(DType_t::FP32);
  graph.add_layer(fp32_dense);

  DenseLayer bf16_dense(input_dim, output_dim, false, "bf16_dense");
  bf16_dense.set_io_dtype(DType_t::BF16);
  bf16_dense.set_param_dtype(DType_t::BF16);
  graph.add_layer(bf16_dense);

  graph.compile(allocator);

  auto bf16_params = bf16_dense.parameters();
  auto fp32_params = fp32_dense.parameters();
  for (size_t i = 0; i < bf16_params.size(); ++i) {
    bf16_params[i]->copy_to(fp32_params[i]);
  }

  Tensor bf16_input = make_tensor(DType_t::BF16, {batch_size, input_dim}, getHost());
  bf16_input->fill_random_uniform(0.0f, 1.0f);
  Tensor fp32_input = make_tensor(DType_t::FP32, {batch_size, input_dim}, getHost());

  bf16 *input_data = bf16_input->data_as<bf16>();
  float *input_data_fp32 = fp32_input->data_as<float>();
  for (size_t i = 0; i < bf16_input->size(); ++i) {
    input_data_fp32[i] = static_cast<float>(input_data[i]);
  }

  Tensor input_fp32 = fp32_input->to_device(getGPU());
  Tensor input_bf16 = bf16_input->to_device(getGPU());

  Tensor output_fp32, output_bf16;
  output_fp32 = make_tensor(DType_t::FP32, {batch_size, output_dim}, getGPU());
  output_bf16 = make_tensor(DType_t::BF16, {batch_size, output_dim}, getGPU());

  fp32_dense.forward({input_fp32}, {output_fp32});
  bf16_dense.forward({input_bf16}, {output_bf16});

  Tensor cpu_output_fp32 = output_fp32->to_host();
  Tensor cpu_output_bf16 = output_bf16->to_host();

  float *output_data_fp32 = cpu_output_fp32->data_as<float>();
  bf16 *output_data_bf16 = cpu_output_bf16->data_as<bf16>();
  constexpr double tolerance = 2e-3;
  for (size_t i = 0; i < cpu_output_fp32->size(); ++i) {
    EXPECT_NEAR(static_cast<double>(output_data_fp32[i]), static_cast<double>(output_data_bf16[i]),
                tolerance)
        << "At index " << i;
  }

  Tensor target_fp32 = make_tensor(DType_t::FP32, {batch_size, output_dim});
  Tensor target_bf16 = make_tensor(DType_t::BF16, {batch_size, output_dim});
  target_fp32->fill(0.0f);
  target_bf16->fill(bf16(0.0f));

  for (size_t i = 0; i < batch_size; ++i) {
    target_fp32->at<float>({i, i % output_dim}) = 1.0f;
    target_bf16->at<bf16>({i, i % output_dim}) = bf16(1.0f);
  }

  auto criterion = LossFactory::create_logsoftmax_crossentropy();

  auto gradient_fp32 = make_tensor(DType_t::FP32, {batch_size, output_dim});
  auto gradient_bf16 = make_tensor(DType_t::BF16, {batch_size, output_dim});

  criterion->compute_gradient(cpu_output_fp32, target_fp32, gradient_fp32);
  criterion->compute_gradient(cpu_output_bf16, target_bf16, gradient_bf16);

  auto gpu_gradient_fp32 = gradient_fp32->to_device(getGPU());
  auto gpu_gradient_bf16 = gradient_bf16->to_device(getGPU());

  Tensor grad_input_bf16 = make_tensor(DType_t::BF16, {batch_size, input_dim}, getGPU());
  Tensor grad_input_fp32 = make_tensor(DType_t::FP32, {batch_size, input_dim}, getGPU());

  bf16_dense.backward({gpu_gradient_bf16}, {grad_input_bf16});
  fp32_dense.backward({gpu_gradient_fp32}, {grad_input_fp32});

  Tensor cpu_grad_input_fp32 = grad_input_fp32->to_host();
  Tensor cpu_grad_input_bf16 = grad_input_bf16->to_host();
  float *grad_input_data_fp32 = cpu_grad_input_fp32->data_as<float>();
  bf16 *grad_input_data_bf16 = cpu_grad_input_bf16->data_as<bf16>();
  for (size_t i = 0; i < cpu_grad_input_fp32->size(); ++i) {
    EXPECT_NEAR(static_cast<double>(grad_input_data_fp32[i]),
                static_cast<double>(grad_input_data_bf16[i]), tolerance)
        << "At index " << i;
  }
}

TEST_F(BF16Test, Attention) {
  constexpr size_t batch_size = 8;
  constexpr size_t seq_len = 16;
  constexpr size_t embed_dim = 16;
  constexpr size_t num_heads = 4;
  auto &allocator = PoolAllocator::instance(getGPU(), defaultFlowHandle);
  Graph graph;

  AttentionBlock fp32_attention(embed_dim, num_heads, false, "fp32_attention");
  fp32_attention.set_io_dtype(DType_t::FP32);
  graph.add_layer(fp32_attention);

  AttentionBlock bf16_attention(embed_dim, num_heads, false, "bf16_attention");
  bf16_attention.set_io_dtype(DType_t::BF16);
  bf16_attention.set_param_dtype(DType_t::BF16);
  graph.add_layer(bf16_attention);

  graph.compile(allocator);

  auto bf16_params = bf16_attention.parameters();
  auto fp32_params = fp32_attention.parameters();
  for (size_t i = 0; i < bf16_params.size(); ++i) {
    Tensor cpu_bf16_param = bf16_params[i]->to_host();
    Tensor cpu_fp32_param = fp32_params[i]->to_host();
    bf16 *bf16_data = cpu_bf16_param->data_as<bf16>();
    float *fp32_data = cpu_fp32_param->data_as<float>();
    for (size_t j = 0; j < cpu_bf16_param->size(); ++j) {
      fp32_data[j] = static_cast<float>(bf16_data[j]);
    }
    cpu_fp32_param->copy_to(fp32_params[i]);
  }

  Tensor bf16_input = make_tensor(DType_t::BF16, {batch_size, seq_len, embed_dim}, getHost());
  bf16_input->fill_random_uniform(0.0f, 1.0f);
  Tensor fp32_input = make_tensor(DType_t::FP32, {batch_size, seq_len, embed_dim}, getHost());

  bf16 *input_data = bf16_input->data_as<bf16>();
  float *input_data_fp32 = fp32_input->data_as<float>();
  for (size_t i = 0; i < bf16_input->size(); ++i) {
    input_data_fp32[i] = static_cast<float>(input_data[i]);
  }

  Tensor input_fp32 = fp32_input->to_device(getGPU());
  Tensor input_bf16 = bf16_input->to_device(getGPU());

  Tensor output_fp32, output_bf16;
  output_fp32 = make_tensor(DType_t::FP32, {batch_size, seq_len, embed_dim}, getGPU());
  output_bf16 = make_tensor(DType_t::BF16, {batch_size, seq_len, embed_dim}, getGPU());

  fp32_attention.forward({input_fp32}, {output_fp32});
  bf16_attention.forward({input_bf16}, {output_bf16});

  Tensor cpu_output_fp32 = output_fp32->to_host();
  Tensor cpu_output_bf16 = output_bf16->to_host();

  float *output_data_fp32 = cpu_output_fp32->data_as<float>();
  bf16 *output_data_bf16 = cpu_output_bf16->data_as<bf16>();
  constexpr double tolerance = 2e-3;
  for (size_t i = 0; i < cpu_output_fp32->size(); ++i) {
    EXPECT_NEAR(static_cast<double>(output_data_fp32[i]), static_cast<double>(output_data_bf16[i]),
                tolerance)
        << "At index " << i;
  }

  Tensor target_fp32 = make_tensor(DType_t::FP32, {batch_size, seq_len, embed_dim});
  Tensor target_bf16 = make_tensor(DType_t::BF16, {batch_size, seq_len, embed_dim});
  target_fp32->fill(0.0f);
  target_bf16->fill(bf16(0.0f));

  for (size_t i = 0; i < 32; ++i) {
    target_fp32->at<float>({i, i % 16, i / 16}) = 1.0f;
    target_bf16->at<bf16>({i, i % 16, i / 16}) = bf16(1.0f);
  }

  auto criterion = LossFactory::create_logsoftmax_crossentropy();

  auto gradient_fp32 = make_tensor(DType_t::FP32, {batch_size, seq_len, embed_dim});
  auto gradient_bf16 = make_tensor(DType_t::BF16, {batch_size, seq_len, embed_dim});

  criterion->compute_gradient(cpu_output_fp32, target_fp32, gradient_fp32);
  criterion->compute_gradient(cpu_output_bf16, target_bf16, gradient_bf16);

  auto gpu_gradient_fp32 = gradient_fp32->to_device(getGPU());
  auto gpu_gradient_bf16 = gradient_bf16->to_device(getGPU());

  Tensor grad_input_bf16 = make_tensor(DType_t::BF16, {batch_size, seq_len, embed_dim}, getGPU());
  Tensor grad_input_fp32 = make_tensor(DType_t::FP32, {batch_size, seq_len, embed_dim}, getGPU());

  bf16_attention.backward({gpu_gradient_bf16}, {grad_input_bf16});
  fp32_attention.backward({gpu_gradient_fp32}, {grad_input_fp32});

  Tensor cpu_grad_input_fp32 = grad_input_fp32->to_host();
  Tensor cpu_grad_input_bf16 = grad_input_bf16->to_host();
  float *grad_input_data_fp32 = cpu_grad_input_fp32->data_as<float>();
  bf16 *grad_input_data_bf16 = cpu_grad_input_bf16->data_as<bf16>();
  for (size_t i = 0; i < cpu_grad_input_fp32->size(); ++i) {
    EXPECT_NEAR(static_cast<double>(grad_input_data_fp32[i]),
                static_cast<double>(grad_input_data_bf16[i]), tolerance)
        << "At index " << i;
  }
}
