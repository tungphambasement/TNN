/*
 * Copyright (c) 2025 Tung D. Pham
 *
 * This software is licensed under the MIT License. See the LICENSE file in the
 * project root for the full license text.
 */
#pragma once

#include "nn/train.hpp"
#include "pipeline/coordinator.hpp"
#include "threading/thread_wrapper.hpp"

namespace tnn {

inline ClassResult train_semi_async_epoch(Coordinator &coordinator,
                                          BaseDataLoader<float> &train_loader,
                                          size_t progress_print_interval) {
  Tensor<float> batch_data, batch_labels;

  size_t batch_index = 0;

  auto epoch_start = std::chrono::high_resolution_clock::now();

  float total_loss = 0.0f;

  coordinator.set_training(true);

  while (train_loader.get_next_batch(batch_data, batch_labels)) {
    // Split batch into micro-batches
    std::vector<Tensor<float>> micro_batch_inputs;
    split(batch_data, micro_batch_inputs, coordinator.num_microbatches());
    std::vector<Tensor<float>> micro_batch_labels;
    split(batch_labels, micro_batch_labels, coordinator.num_microbatches());

    auto process_start = std::chrono::high_resolution_clock::now();
    // Perform forward, compute loss, and backward asynchronously.
    total_loss += coordinator.async_process_batch(micro_batch_inputs, micro_batch_labels);
    auto process_end = std::chrono::high_resolution_clock::now();
    auto process_duration =
        std::chrono::duration_cast<std::chrono::microseconds>(process_end - process_start);

    coordinator.update_parameters();

    if ((batch_index + 1) % progress_print_interval == 0) {

      std::cout << "Async process completed in " << process_duration.count() << " microseconds"
                << std::endl;
      std::cout << "Average Loss after " << (batch_index + 1)
                << " batches: " << (total_loss / (batch_index + 1)) << std::endl;
      std::cout << "Batch " << batch_index + 1 << "/"
                << train_loader.size() / train_loader.get_batch_size() << std::endl;
    }
    ++batch_index;
  }

  auto epoch_end = std::chrono::high_resolution_clock::now();
  auto epoch_duration =
      std::chrono::duration_cast<std::chrono::milliseconds>(epoch_end - epoch_start);
  std::cout << "\nEpoch completed in " << epoch_duration.count() << " milliseconds" << std::endl;
  return {total_loss / batch_index, -1.0f};
}

inline ClassResult validate_semi_async_epoch(Coordinator &coordinator,
                                             BaseDataLoader<float> &test_loader) {
  Tensor<float> batch_data, batch_labels;
  float total_val_loss = 0.0f;
  float total_val_correct = 0.0f;
  int val_batches = 0;

  coordinator.set_training(false);

  while (test_loader.get_next_batch(batch_data, batch_labels)) {
    std::vector<Tensor<float>> micro_batch_inputs;
    split(batch_data, micro_batch_inputs, coordinator.num_microbatches());

    std::vector<Tensor<float>> micro_batch_labels;
    split(batch_labels, micro_batch_labels, coordinator.num_microbatches());

    for (size_t i = 0; i < micro_batch_inputs.size(); ++i) {
      coordinator.forward(std::move(micro_batch_inputs[i]), i);
    }

    coordinator.join(CommandType::FORWARD_JOB, coordinator.num_microbatches(), 60);

    std::vector<Message> all_messages = coordinator.dequeue_all_messages(CommandType::FORWARD_JOB);

    if (all_messages.size() != static_cast<size_t>(coordinator.num_microbatches())) {
      throw std::runtime_error(
          "Unexpected number of messages: " + std::to_string(all_messages.size()) +
          ", expected: " + std::to_string(coordinator.num_microbatches()));
    }

    std::vector<Job<float> *> forward_jobs;
    for (auto &message : all_messages) {
      if (message.header().command_type == CommandType::FORWARD_JOB) {
        forward_jobs.push_back(&message.get<Job<float>>());
      }
    }

    auto val_loss = 0.0f;
    auto val_correct = 0.0f;

    for (auto &job : forward_jobs) {
      val_loss += coordinator.compute_loss(job->data, micro_batch_labels[job->micro_batch_id]);
      val_correct += compute_class_corrects(job->data, micro_batch_labels[job->micro_batch_id]);
    }
    // Normalize loss by number of microbatches to match training loss semantics
    if (coordinator.num_microbatches() > 0) {
      val_loss /= static_cast<float>(coordinator.num_microbatches());
    }
    total_val_loss += val_loss;
    total_val_correct += val_correct;
    ++val_batches;
  }

  std::cout << "Validation completed." << std::endl;
  std::cout << "Average Validation Loss: " << (total_val_loss / val_batches)
            << ", Average Validation Accuracy: "
            << (total_val_correct / test_loader.size()) * 100.0f << "%" << std::endl;
  return {static_cast<float>(total_val_loss / val_batches),
          static_cast<float>((total_val_correct / test_loader.size()) * 100.0f)};
}

inline void train_model(Coordinator &coordinator, BaseDataLoader<float> &train_loader,
                        BaseDataLoader<float> &test_loader,
                        TrainingConfig config = TrainingConfig()) {
  ThreadWrapper thread_wrapper({config.num_threads});
  coordinator.set_num_microbatches(config.num_microbatches);

  thread_wrapper.execute([&]() -> void {
    for (int epoch = 0; epoch < config.epochs; ++epoch) {
      train_loader.prepare_batches(config.batch_size);
      test_loader.prepare_batches(config.batch_size);
      std::cout << "Epoch " << (epoch + 1) << "/" << config.epochs << " ===" << std::endl;
      train_loader.reset();
      test_loader.reset();
      train_loader.shuffle();

      train_semi_async_epoch(coordinator, train_loader, config.progress_print_interval);

      validate_semi_async_epoch(coordinator, test_loader);
    }
  });
}

} // namespace tnn